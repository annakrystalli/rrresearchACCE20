# Paths and Project structure {#path-proj-str}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(magrittr)
```



## Project Data

We're in our new project so the first thing we need to do is get the data we'll be working with. This is a common start to any project where you start with a few data files, These might be generated through your data, given by others or published data products and you might need to clean, wrangle and combine them together to perform your analysis. 

> Q: Where should I save my raw data files?


### conventions: Data management 

1. Store raw data in `data-raw/`: raw inputs to any pre-processing, read only. 
  - Keep any processing scripts in the same folder
  - Whether and where you publish data depends on size and copyright considerations.
2. Store analytical data in `data/`: any clean, processed data that is used as the input to the analysis.
  - Should be published along side analysis.

## Setting up a `data-raw/` directory

We **start by creating a `data-raw` directory** in the root of our project. We can use `usethis` function `usethis::use_data_raw()`. This creates the `data-raw` directory and an `.R` script within where we can save code that turns raw data into analytical data in the `data/` folder. 

We can supply a name for the analytical dataset we'll be creating in our script which automatically names the `.R` script for easy provenance tracking. In this case, we'll be calling it `individual.csv` so let's use `"individual"` for our name.


```{r, eval=FALSE}
usethis::use_data_raw(name = "individual")
```

```r
✔ Setting active project to '/Users/Anna/Desktop/wood-survey'
✔ Creating 'data-raw/'
✔ Adding '^data-raw$' to '.Rbuildignore'
✔ Writing 'data-raw/individual.R'
● Modify 'data-raw/individual.R'
● Finish the data preparation script in 'data-raw/individual.R'
● Use `usethis::use_data()` to add prepared data to package
```

The **`data-raw/individual.R`** script created contains:

```r
## code to prepare `individual` dataset goes here

usethis::use_data("individual")

```

We will use this file to perform the necessary preprocessing on our raw data. 

```{r, echo=FALSE, eval=FALSE}
fs::dir_delete(here::here("data-raw", "wood-survey-data-master")) 
```


### Download data

Now that we've got our `data-raw` folder, let's download our data into it using function `usethis::use_course()` and supplying it with the url to the materials repository (bit.ly/wood-survey-data) and the path to the directory we want the materials saved into (`"data-raw"`).

```{r, eval=FALSE}
usethis::use_course("bit.ly/wood-survey-data",
           destdir = "data-raw")
```

```bash
✔ Downloading from 'https://github.com/annakrystalli/wood-survey-data/archive/master.zip'
Downloaded: 0.03 MB  
✔ Download stored in 'data-raw/wood-survey-data-master.zip'
✔ Unpacking ZIP file into 'wood-survey-data-master/' (13 files extracted)
Shall we delete the ZIP file ('wood-survey-data-master.zip')?

1: Negative
2: Absolutely not
3: I agree

Selection: 3
✔ Deleting 'wood-survey-data-master.zip'
✔ Opening 'wood-survey-data-master/' in the file manager
```


## NEON Data

The downloaded folder contains a **subset of data from the NEON Woody plant vegetation survey**.


**Citation:**
_National Ecological Observatory Network. 2020. Data Products: DP1.10098.001.  Provisional data downloaded from http://data.neonscience.org on 2020-01-15. Battelle, Boulder, CO, USA_

This data product was downloaded from the [NEON data portal](http://data.neonscience.org/browse-data) and contains quality-controlled data from in-situ measurements of live and standing dead woody individuals and shrub groups, from all terrestrial NEON sites with qualifying woody vegetation.

Surveys of each site are completed once every 3 years.

Let's have a look at what we've downloaded:

```
.
├── R
├── data-raw
│   ├── individual.R
│   └── wood-survey-data-master
│       ├── NEON_vst_variables.csv
│       ├── README.md
│       ├── individual [67 entries exceeds filelimit, not opening dir]
│       ├── methods
│       │   ├── NEON.DOC.000914vB.pdf
│       │   ├── NEON.DOC.000987vH.pdf
│       │   └── NEON_vegStructure_userGuide_vA.pdf
│       ├── vst_mappingandtagging.csv
│       └── vst_perplotperyear.csv
└── wood-survey.Rproj
```


The important files for the analysis we want to perform are 

```
├── individual [67 entries exceeds filelimit, not opening dir]
├── vst_mappingandtagging.csv
└── vst_perplotperyear.csv
```

- **`vst_perplotperyear`**: Plot level metadata, including plot geolocation, 
  - one record per `plotID` per `eventID`, 
  - describe the presence/absence of woody growth forms
  - sampling area utilized for each growth form. 
  
- **`vst_mappingandtagging`**: Mapping, identifying and tagging of individual stems for remeasurement 
  - one record per `individualID`, 
  - data invariant through time, including `tagID`, `taxonID` and mapped location. 
  - Records can be linked to `vst_perplotperyear` via the `plotID` and `eventID` fields. 
  
- **`vst_apparentindividual`**: Biomass and productivity measurements of apparent individuals.
  - may contain multiple records per individuals
  - includes growth form, structure
  - currently in separate files contained in `individual/`
  - may be linked
    - `vst_mappingandtagging` records via `individualID`
    - `vst_perplotperyear` via the `plotID` and `eventID` fields.

<div class="alert alert-secondary"> 

`r icon::fontawesome("tasks")`  As our first challenge, we are going to combined all the files in `individual/` into a single analytical data file!

</div>

## Paths

First let's investigate our data. We want to access the files so we need to give R paths in order to load the data. We can work with the file system programmatically through R.

- `here`: Use `here::here()` to create paths relative to the project root directory.
  - portable
  - independent of the where code is evaluated or saved. 


Let's start by creating a path to the downloaded data directory using `here`. 
```{r}
raw_data_path <- here::here("data-raw", "wood-survey-data-master")
raw_data_path
```

```r
"/Users/Anna/Desktop/wood-survey/data-raw/wood-survey-data-master"
```

We can use `raw_data_path` as our basis for specifying paths to files within it. There's a number of ways we can do this in R but I wanted to introduce you to package `fs`. It has a nice interface and extensive functionality.

```{r}
fs::path(raw_data_path, "individual")
```

```r
/Users/Anna/Desktop/wood-survey/data-raw/wood-survey-data-master/individual
```


Let's now use function `dir_ls` to get a character vector of paths to all the individual files in directory `individual`.

```{r, eval=FALSE}
individual_paths <- fs::dir_ls(fs::path(raw_data_path, "individual"))
head(individual_paths)
```

```{r, echo=FALSE}
individual_paths <- fs::dir_ls(fs::path(raw_data_path, "individual"))
individual_paths_proj <- fs::path("~/Desktop", "wood-survey", "data-raw", "wood-survey-data-master", "individual")
head(fs::dir_ls(individual_paths_proj))
```

We can check how many files we've got:

```{r}
length(individual_paths)
```

We can now use this vector of paths to read in files. Let's read the first file in and check it out. We use function `read_csv()` from `readr` package which reads comma delimited files into tibbles.

```{r}
indiv_df <- readr::read_csv(individual_paths[1])
indiv_df
```

Run `?read_delim` for more details on reading in tabular data.

## Basic checks

Let's perform some of the basic checks we learnt before we proceed.

```{r, eval=FALSE}
View(indiv_df)
```

```{r, echo=FALSE}
knitr::include_graphics("assets/indiv_df.png", error = FALSE)
```

```{r}
names(indiv_df)
```

```{r, echo=FALSE}
str(indiv_df)
```

```{r, echo=FALSE}
summary(indiv_df)
```

Everything looks good. So let's move onto the next step of reading in all the files and combining them together. To do this, we'll examine the principles of **Iteration**.